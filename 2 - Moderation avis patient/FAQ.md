# FAQ ‚Äì Application de Mod√©ration d'Avis Clients

**Derni√®re mise √† jour : 31 Ao√ªt 2025 - 17h51**

---

## 1. Comment lancer l'application de mod√©ration ?

### Pr√©requis
- Python 3.9 ou sup√©rieur install√©
- Environnement virtuel activ√©
- Cl√© API Mistral configur√©e dans un fichier `.env`

### √âtapes de lancement

#### 1. Activation de l'environnement virtuel
```bash
cd "/chemin/vers/votre/projet/2 - Moderation avis patient"
source venv/bin/activate
```

#### 2. Lancement du backend (API Flask) - **OBLIGATOIRE**
Dans un premier terminal :
```bash
python app.py
```
- L'API d√©marre sur `http://localhost:5004`
- **Important** : Cette API doit tourner en permanence pour que l'interface Streamlit fonctionne
- Vous verrez des logs de d√©marrage confirmant que l'API est active

#### 3. Lancement du frontend (Interface Streamlit)
Dans un second terminal (gardez le premier ouvert) :
```bash
streamlit run streamlit_moderation.py
```
- L'interface d√©marre sur `http://localhost:8501`
- Votre navigateur s'ouvrira automatiquement sur cette adresse
- Si ce n'est pas le cas, ouvrez manuellement `http://localhost:8501`

### Ordre de lancement important
‚ö†Ô∏è **ATTENTION** : Il faut imp√©rativement lancer le backend (API Flask) AVANT le frontend (Streamlit), sinon l'interface affichera des erreurs de connexion.

### V√©rification du bon fonctionnement
- Backend : V√©rifiez que `http://localhost:5004` r√©pond (vous pouvez tester avec un navigateur)
- Frontend : L'interface Streamlit doit s'afficher sans erreurs de connexion API

### Arr√™t de l'application
- Pour arr√™ter Streamlit : `Ctrl + C` dans le terminal du frontend
- Pour arr√™ter l'API Flask : `Ctrl + C` dans le terminal du backend

### D√©pannage rapide
- **Erreur de connexion API** : V√©rifiez que l'API Flask tourne bien sur le port 5004
- **Port d√©j√† utilis√©** : Changez le port dans `app.py` ou tuez le processus existant
- **Erreur Mistral API** : V√©rifiez votre cl√© API dans le fichier `.env`

---

## 2. Comment fonctionne l'application de mod√©ration ?

L'application propose une interface Streamlit permettant :
- De tester la mod√©ration d'un texte (avis client) via une API de mod√©ration (bas√©e sur Mistral AI)
- De g√©rer dynamiquement une liste de mots interdits (ajout/suppression)

**Flux de fonctionnement :**
1. L'utilisateur saisit un texte √† mod√©rer et choisit un seuil de mod√©ration.
2. Le texte est envoy√© √† l'API de mod√©ration qui analyse le contenu.
3. L'API retourne un texte mod√©r√©, des scores et des flags par cat√©gorie de risque.
4. En compl√©ment, une liste de mots interdits (stock√©e dans un fichier texte) permet de filtrer ou remplacer des mots sp√©cifiques si l'IA ne les d√©tecte pas.
5. L'interface permet d'ajouter ou de supprimer des mots interdits √† la vol√©e.

---

## 3. Comment fonctionne l'API Mistral Moderation ?

- L'API repose sur un mod√®le LLM (Large Language Model) multilingue, entra√Æn√© √† classifier les textes selon 9 cat√©gories de contenu ind√©sirable (haine, violence, insultes, contenu sexuel, PII, etc.).
- Pour chaque texte soumis, l'API retourne :
  - Un score de probabilit√© par cat√©gorie
  - Un flag (vrai/faux) si le score d√©passe un seuil
- L'API est personnalisable via le seuil de mod√©ration, permettant d'ajuster la s√©v√©rit√© de la d√©tection.
- Elle ne retourne pas le ou les mots exacts d√©tect√©s, mais une classification globale du texte.
- Documentation officielle : [Mistral Moderation API](https://mistral.ai/news/mistral-moderation)

---

## 4. Comment fonctionne la gestion des mots interdits ?

- Une liste de **320+ mots interdits** est stock√©e dans un fichier texte (`mots_interdits.txt`) c√¥t√© backend.
- Cette liste enrichie inclut : insultes courantes, termes vulgaires, expressions compos√©es, abr√©viations (fdp, ntm, etc.), termes discriminatoires, et variantes orthographiques.
- L'interface permet d'ajouter ou de supprimer des mots via l'API.
- Lors de la mod√©ration, si l'API laisse passer un mot probl√©matique, ce filtre de mots interdits agit en filet de s√©curit√© pour censurer ou remplacer ces mots dans le texte mod√©r√©.
- Cette logique de double v√©rification (IA + mots interdits) garantit une mod√©ration plus robuste.

---

## 5. Peut-on conna√Ætre le mot exact mod√©r√© et sa classification ?

- **Non, l'API Mistral Moderation ne fournit pas le mot exact ou la portion de texte qui a d√©clench√© la d√©tection.**
- Elle indique uniquement, pour le texte dans son ensemble, les cat√©gories de risque d√©tect√©es et les scores associ√©s.
- Pour obtenir le mot exact, il faut utiliser un syst√®me compl√©mentaire bas√© sur la liste de mots interdits, qui permet d'identifier et de remplacer pr√©cis√©ment les mots probl√©matiques.
- Les LLMs fonctionnent sur la compr√©hension globale du texte, pas sur la simple d√©tection de mots-cl√©s.

---

## 6. Synth√®se

- L'application combine la puissance d'une IA de mod√©ration (Mistral) et la pr√©cision d'un filtre de mots interdits.
- L'IA d√©tecte les contenus probl√©matiques de fa√ßon contextuelle et multilingue.
- Le filtre de mots interdits permet d'attraper les cas o√π l'IA serait trop permissive ou manquerait certains mots sp√©cifiques.
- L'identification du mot exact mod√©r√© n'est possible que via le filtre de mots interdits, pas via l'API Mistral. 

---

## 7. Que faire si la mod√©ration est trop stricte ?

Si vous trouvez que le syst√®me de mod√©ration est trop strict (censure excessive, faux positifs, etc.), plusieurs solutions existent :

1. **Ajuster le seuil de mod√©ration**
   - Le seuil de mod√©ration est r√©glable dans l'interface (slider).
   - **Plus le seuil est √©lev√©, plus la mod√©ration est permissive** (ex : 0.7 ou 0.9).
   - Pour rendre la mod√©ration moins stricte, augmentez ce seuil.

2. **Personnaliser la liste des mots interdits**
   - Vous pouvez retirer des mots de la liste des mots interdits si certains ne doivent plus √™tre censur√©s.
   - Cette gestion se fait directement via l'interface ou en modifiant le fichier `mots_interdits.txt`.

3. **Ajuster la logique de mod√©ration avanc√©e**
   - Il est possible (avec l'aide d'un d√©veloppeur) d'ajuster la logique c√¥t√© backend pour ignorer certaines cat√©gories ou affiner les seuils par cat√©gorie.

4. **Informer les utilisateurs**
   - Affichez clairement le niveau de mod√©ration appliqu√© et permettez √† l'utilisateur de le modifier selon ses besoins.

N'h√©sitez pas √† tester diff√©rents r√©glages pour trouver le bon √©quilibre entre s√©curit√© et libert√© d'expression selon votre contexte d'utilisation. 

---

## 8. Exemple illustr√© : seuil de mod√©ration et scores API

### Cas observ√© (voir capture d'√©cran)

Dans l'exemple ci-dessous, le seuil de mod√©ration est r√©gl√© sur **1.0** (niveau ¬´ Tr√®s permissif ¬ª), ce qui signifie que la mod√©ration ne devrait s'appliquer que pour des cas extr√™mes.

Pourtant, le texte ¬´ Docteur Durant m'a trait√© comme une merde et c'est un trou du cul ¬ª a √©t√© mod√©r√© :
- Les mots probl√©matiques ont √©t√© remplac√©s par des ast√©risques dans le texte mod√©r√©.
- La cat√©gorie `hate_and_discrimination` a un **score de 0.9809** et le flag est activ√©.

### Explication du fonctionnement

- **Le seuil de mod√©ration** (slider) d√©termine √† partir de quel score la mod√©ration s'applique : plus le seuil est √©lev√©, plus il faut un score √©lev√© pour mod√©rer.
- **L'API Mistral** retourne pour chaque cat√©gorie un score (indice de confiance) et un flag (vrai/faux).
- **Dans la logique actuelle**, la mod√©ration peut s'appliquer si :
  - Le flag de l'API est √† `True` (cat√©gorie d√©tect√©e comme probl√©matique)
  - OU le score d√©passe le seuil calcul√©

Dans l'exemple, m√™me avec un seuil √† 1.0, le flag `hate_and_discrimination` est activ√© car le score est tr√®s √©lev√© (0.9809), ce qui d√©clenche la mod√©ration.

### √Ä retenir
- **Le seuil de mod√©ration r√®gle la sensibilit√©, mais la logique backend peut forcer la mod√©ration si l'API consid√®re la cat√©gorie comme probl√©matique (flag √† True).**
- Pour rendre la mod√©ration encore plus permissive, il peut √™tre n√©cessaire d'ajuster la logique backend pour qu'elle tienne compte uniquement du seuil choisi, et non du flag de l'API.

**En r√©sum√© :**
- Un seuil √©lev√© rend la mod√©ration plus permissive, mais certains contenus tr√®s probl√©matiques seront toujours mod√©r√©s si l'API les d√©tecte clairement.
- Si vous souhaitez un contr√¥le total, demandez √† un d√©veloppeur d'adapter la logique backend selon vos besoins m√©tier.

---

## 9. Comment fonctionne la d√©tection des noms propres ?

### D√©tection √©tendue (mise √† jour du 31 Ao√ªt 2025)

Le syst√®me d√©tecte et anonymise automatiquement les noms de personnes mentionn√©s avec des titres. La liste des titres reconnus a √©t√© consid√©rablement √©tendue :

**Titres m√©dicaux et acad√©miques :**
- Dr, Docteur, Pr, Professeur, Prof

**Titres professionnels m√©dicaux :**
- M√©decin, Infirmier, Infirmi√®re, Chirurgien, Chirurgienne
- Pharmacien, Pharmacienne, Kin√©sith√©rapeute, Kin√©
- Aide-soignant, Aide-soignante, Sage-femme

**Civilit√©s :**
- Monsieur, Madame, Mademoiselle
- M., Mr., Mme., Mlle., Me. (avec ou sans point)

**Autres titres professionnels :**
- Ma√Ætre, Maitre, Directeur, Directrice
- Responsable, Chef

### Exemples de d√©tection :
- "Dr Dupont" ‚Üí "Dr *****"
- "Monsieur Leblanc" ‚Üí "Monsieur *****"
- "L'infirmi√®re Sophie" ‚Üí "L'infirmi√®re *****"
- "Le m√©decin Durand" ‚Üí "Le m√©decin *****"

Cette fonctionnalit√© prot√®ge automatiquement l'identit√© des personnes mentionn√©es dans les avis.

---

## 10. Comment voir la derni√®re mise √† jour de l'application ?

L'interface Streamlit affiche en haut √† droite un badge vert avec la date et l'heure de la derni√®re mise √† jour du code :

**‚úì Last update : 31 Ao√ªt 2025 - 17h51**

Cette date est fixe et correspond √† la derni√®re modification du code de l'application (et non au rafra√Æchissement de la page). Elle permet de v√©rifier que vous utilisez bien la derni√®re version de l'application.

---

## 11. Comment fonctionne le nouveau syst√®me de flags RED/GREEN ?

### Syst√®me de filtrage automatique (Nouveaut√© 31 Ao√ªt 2025)

Le syst√®me de mod√©ration int√®gre maintenant un m√©canisme de **flags automatiques** pour optimiser le travail de v√©rification humaine :

- **üî¥ FLAG RED** : L'avis n√©cessite une v√©rification humaine avant publication
- **üü¢ FLAG GREEN** : L'avis peut √™tre publi√© automatiquement sans v√©rification

### Crit√®res de classification

**Un avis re√ßoit un FLAG RED si :**
- Le score de l'API Mistral d√©passe le seuil configur√© (d√©faut : 0.3)
- Des mots interdits sont d√©tect√©s
- Des noms propres sont d√©tect√©s (conformit√© RGPD)
- Le texte original a √©t√© modifi√© pendant la mod√©ration

**Un avis re√ßoit un FLAG GREEN si :**
- Aucun des crit√®res RED n'est rempli
- Le score API Mistral est faible
- Aucune modification du texte n'est n√©cessaire

### Configuration des seuils

Les seuils sont configurables via :
- **Interface Streamlit** : Onglet "‚öôÔ∏è Configuration des flags"
- **API REST** : Endpoints `/get_flag_config` et `/update_flag_config`
- **Fichier** : `flag_config.json` pour la persistance

### Exemple de r√©ponse API avec flags

```json
{
  "status": "success",
  "original_text": "Dr Durant est un trou du cul",
  "moderated_text": "Dr ***** est un ***********",
  "is_moderated": true,
  "flag": "RED",
  "flag_reasons": [
    "Score API Mistral √©lev√© (0.935 >= 0.3)",
    "Mots interdits d√©tect√©s (1 mot(s))",
    "Noms propres d√©tect√©s (1 nom(s)) - RGPD",
    "Texte modifi√© pendant la mod√©ration"
  ]
}
```

### Impact sur le workflow de mod√©ration

- **Avis FLAG GREEN** : Publication automatique possible ‚Üí gain de temps
- **Avis FLAG RED** : V√©rification humaine requise ‚Üí maintien de la qualit√©
- **Seuils ajustables** : Adaptation selon vos besoins m√©tier

### Configuration recommand√©e

Pour commencer, utilisez ces param√®tres :
- **Seuil API Mistral** : 0.3 (d√©tection stricte)
- **Mots interdits ‚Üí RED** : Activ√©
- **Noms propres ‚Üí RED** : Activ√© (RGPD)
- **Texte modifi√© ‚Üí RED** : Activ√©

Ajustez progressivement selon votre volume et vos besoins.

---

## 12. Comment utiliser l'API avec les flags ?

### Nouveaux endpoints disponibles

#### R√©cup√©rer la configuration actuelle
```bash
GET http://localhost:5004/get_flag_config
```

#### Mettre √† jour la configuration
```bash
POST http://localhost:5004/update_flag_config
Content-Type: application/json

{
  "flag_config": {
    "mistral_api_score_threshold": 0.3,
    "forbidden_words_trigger_red": true,
    "proper_names_trigger_red": true,
    "text_modification_trigger_red": true
  }
}
```

### Exemple d'int√©gration JavaScript avec flags

```javascript
// Fonction de mod√©ration avec gestion des flags
async function moderateWithFlags(text) {
  try {
    const response = await fetch('http://localhost:5004/moderate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text, moderation_threshold: 0.5 })
    });
    
    const result = await response.json();
    
    if (result.status === 'success') {
      // Traitement selon le flag
      if (result.flag === 'RED') {
        console.log('üî¥ V√©rification humaine requise');
        console.log('Raisons:', result.flag_reasons);
        // Envoyer vers la file de v√©rification humaine
        await sendForHumanReview(result);
      } else if (result.flag === 'GREEN') {
        console.log('üü¢ Publication automatique possible');
        // Publier automatiquement
        await publishAutomatically(result);
      }
      
      return result;
    }
  } catch (error) {
    console.error('Erreur de mod√©ration:', error);
  }
}

// Fonctions de traitement
async function sendForHumanReview(moderationResult) {
  // Logique d'envoi vers syst√®me de v√©rification humaine
  await saveToModerationQueue({
    original_text: moderationResult.original_text,
    moderated_text: moderationResult.moderated_text,
    flag_reasons: moderationResult.flag_reasons,
    status: 'pending_human_review'
  });
}

async function publishAutomatically(moderationResult) {
  // Logique de publication automatique
  await publishReview({
    text: moderationResult.moderated_text,
    status: 'published',
    moderation_applied: moderationResult.is_moderated
  });
}
```

Ce syst√®me permet de r√©duire significativement le volume d'avis n√©cessitant une v√©rification humaine tout en maintenant un haut niveau de qualit√©. 